{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model uses CNNs to classify audio input into instrument classes.\n",
    "\n",
    "General Procedure:\n",
    "\t- Use STFTs to transform audio input into spectral graphs\n",
    "\t- Use spectral graphs as \"images\" to classify into instrument classes\n",
    "\n",
    "Data Format:\n",
    " \t- Data is stored in tfrecord form obtained from the Nsynth dataset: https://magenta.tensorflow.org/datasets/nsynth\n",
    "\n",
    "Based off of aymericdamien's TensorFlow examples: https://github.com/aymericdamien/TensorFlow-Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.framework.python.ops import audio_ops\n",
    "from tensorflow.python import debug as tf_debug\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# For debugging on Windows 10\n",
    "from pyreadline import Readline\n",
    "readline = Readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "LEARNING_RATE = 0.00001\n",
    "NUM_STEPS = 500\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Network Parameters\n",
    "NUM_INPUT = 16384   # spectrogram data input (img shape: 128*128)\n",
    "NUM_CLASSES = 11    # total instrument classes\n",
    "DROPOUT = 0.25      # Dropout, probability to drop a unit\n",
    "\n",
    "# Data paths\n",
    "TRAINING_DATA = \"E:/NSynth/nsynth-train.tfrecord\"\n",
    "TEST_DATA = \"E:/NSynth/nsynth-valid.tfrecord\"\n",
    "EVAL_DATA = \"E:/NSynth/nsynth-test.tfrecord\"\n",
    "MODEL_PATH = \"E:/NSynth/trained_models/\"\n",
    "\n",
    "# Data parameters\n",
    "SAMPLE_RATE = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22. 28.]\n",
      " [49. 64.]]\n"
     ]
    }
   ],
   "source": [
    "# Test GPU presence\n",
    "# If no errors thrown, GPU is being used\n",
    "with tf.device('/gpu:0'):\n",
    "    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "    c = tf.matmul(a, b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print (sess.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the neural network\n",
    "def conv_net(x_dict, n_classes, dropout, reuse, is_training):\n",
    "    \n",
    "    # Define a scope for reusing the variables\n",
    "    with tf.variable_scope('ConvNet', reuse=reuse):\n",
    "        # TF Estimator input is a dict, in case of multiple inputs\n",
    "        x = x_dict['image']\n",
    "\n",
    "        # Spectrogram data input is a 1-D vector of 16384 features (128*128 pixels)\n",
    "        # Reshape to match picture format [Height x Width x Channel]\n",
    "        # Tensor input become 4-D: [Batch Size, Height, Width, Channel]\n",
    "        x = tf.reshape(x, shape=[-1, 128, 128, 1])\n",
    "\n",
    "        # Convolution Layer with 32 filters and a kernel size of 5\n",
    "        conv1 = tf.layers.conv2d(x, 32, 5, activation=tf.nn.relu)\n",
    "        # Max Pooling (down-sampling) with strides of 2 and kernel size of 2\n",
    "        conv1 = tf.layers.max_pooling2d(conv1, 2, 2)\n",
    "\n",
    "        # Convolution Layer with 64 filters and a kernel size of 3\n",
    "        conv2 = tf.layers.conv2d(conv1, 64, 3, activation=tf.nn.relu)\n",
    "        # Max Pooling (down-sampling) with strides of 2 and kernel size of 2\n",
    "        conv2 = tf.layers.max_pooling2d(conv2, 2, 2)\n",
    "\n",
    "        # Flatten the data to a 1-D vector for the fully connected layer\n",
    "        fc1 = tf.contrib.layers.flatten(conv2)\n",
    "\n",
    "        # Fully connected layer (in tf contrib folder for now)\n",
    "        fc1 = tf.layers.dense(fc1, 1024)\n",
    "        # Apply Dropout (if is_training is False, dropout is not applied)\n",
    "        fc1 = tf.layers.dropout(fc1, rate=dropout, training=is_training)\n",
    "\n",
    "        # Output layer, class prediction\n",
    "        out = tf.layers.dense(fc1, n_classes)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model function (following TF Estimator Template)\n",
    "def model_fn(features, labels, mode):\n",
    "    \n",
    "    # Build the neural network\n",
    "    # Because Dropout have different behavior at training and prediction time, we\n",
    "    # need to create 2 distinct computation graphs that still share the same weights.\n",
    "    logits_train = conv_net(features, NUM_CLASSES, DROPOUT, reuse=False, is_training=True)\n",
    "    logits_test = conv_net(features, NUM_CLASSES, DROPOUT, reuse=True, is_training=False)\n",
    "    \n",
    "    # Predictions\n",
    "    pred_classes = tf.argmax(logits_test, axis=1)\n",
    "    pred_probas = tf.nn.softmax(logits_test)\n",
    "    \n",
    "    # If prediction mode, early return\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=pred_classes) \n",
    "        \n",
    "    # Define loss and optimizer\n",
    "#     loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "#         logits=logits_train, labels=tf.cast(labels, dtype=tf.int32)))\n",
    "    labels = tf.reshape(labels, shape=[-1]) # Squeeze labels from 2D to 1D - don't know why they are fed as 2D\n",
    "    print(labels)\n",
    "    loss_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        logits=logits_train, labels=tf.cast(labels, dtype=tf.int32)))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE)\n",
    "    train_op = optimizer.minimize(loss_op, global_step=tf.train.get_global_step())\n",
    "    \n",
    "    # Evaluate the accuracy of the model\n",
    "    acc_op = tf.metrics.accuracy(labels=labels, predictions=pred_classes)\n",
    "    \n",
    "    # TF Estimators requires to return a EstimatorSpec, that specify\n",
    "    # the different ops for training, evaluating, ...\n",
    "    estim_specs = tf.estimator.EstimatorSpec(\n",
    "      mode=mode,\n",
    "      predictions=pred_classes,\n",
    "      loss=loss_op,\n",
    "      train_op=train_op,\n",
    "      eval_metric_ops={'accuracy': acc_op})\n",
    "\n",
    "    return estim_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'E:/NSynth/trained_models/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000243804A9780>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Build the Estimator\n",
    "model = tf.estimator.Estimator(model_fn, model_dir=MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"transpose_image/transpose_image:0\", shape=(128, 128, 1), dtype=float32, device=/device:CPU:0)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "Tensor(\"Reshape:0\", shape=(?,), dtype=int64)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from E:/NSynth/trained_models/model.ckpt-0\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into E:/NSynth/trained_models/model.ckpt.\n",
      "run-start: run #1: 2 fetches; 0 feeds\n",
      "\n",
      "TTTTTT FFFF DDD  BBBB   GGG \n",
      "  TT   F    D  D B   B G    \n",
      "  TT   FFF  D  D BBBB  G  GG\n",
      "  TT   F    D  D B   B G   G\n",
      "  TT   F    DDD  BBBB   GGG \n",
      "\n",
      "TensorFlow version: 1.10.0\n",
      "\n",
      "======================================\n",
      "Session.run() call #1:\n",
      "\n",
      "Fetch(es):\n",
      "  Adam\n",
      "  Mean:0\n",
      "\n",
      "Feed dict:\n",
      "  (Empty)\n",
      "======================================\n",
      "\n",
      "Select one of the following commands to proceed ---->\n",
      "  run:\n",
      "    Execute the run() call with debug tensor-watching\n",
      "  run -n:\n",
      "    Execute the run() call without debug tensor-watching\n",
      "  run -t <T>:\n",
      "    Execute run() calls (T - 1) times without debugging, then execute run() once more with debugging and drop back to the CLI\n",
      "  run -f <filter_name>:\n",
      "    Keep executing run() calls until a dumped tensor passes a given, registered filter (conditional breakpoint mode)\n",
      "    Registered filter(s):\n",
      "        * has_inf_or_nan\n",
      "  invoke_stepper:\n",
      "    Use the node-stepper interface, which allows you to interactively step through nodes involved in the graph run() call and inspect/modify their values\n",
      "\n",
      "For more details, see help..\n",
      "\n",
      "\n",
      "tfdbg> run\n",
      "run-end: run #1: 2 fetches; 0 feeds\n",
      "136 dumped tensor(s):\n",
      "\n",
      "t (ms)      Size (B) Op type                             Tensor name\n",
      "[0.000]     182      Const                               loss/tags:0\n",
      "[0.415]     260      Const                               gradients/ConvNet/dropout/dropout/div_grad/Shape_1:0\n",
      "[1.865]     340      OneShotIterator                     OneShotIterator:0\n",
      "[18.001]    3.35k    VariableV2                          ConvNet/conv2d/kernel/Adam_1:0\n",
      "[18.002]    474      VariableV2                          ConvNet/conv2d_1/bias/Adam:0\n",
      "[18.006]    3.35k    VariableV2                          ConvNet/conv2d/kernel/Adam:0\n",
      "[18.009]    346      VariableV2                          ConvNet/conv2d/bias/Adam_1:0\n",
      "[18.009]    478      VariableV2                          ConvNet/conv2d_1/bias/Adam_1:0\n",
      "[18.012]    342      VariableV2                          ConvNet/conv2d/bias/Adam:0\n",
      "[22.403]    218      Const                               gradients/Mean_grad/Const:0\n",
      "[36.973]    72.23k   VariableV2                          ConvNet/conv2d_1/kernel/Adam:0\n",
      "[39.786]    366      Const                               gradients/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim:0\n",
      "[53.305]    258      Const                               ConvNet/Flatten/flatten/strided_slice/stack_1:0\n",
      "[53.838]    72.24k   VariableV2                          ConvNet/conv2d_1/kernel/Adam_1:0\n",
      "[53.844]    4.21k    VariableV2                          ConvNet/dense/bias/Adam:0\n",
      "[53.878]    44.23k   VariableV2                          ConvNet/dense_1/kernel/Adam_1:0\n",
      "[53.892]    44.22k   VariableV2                          ConvNet/dense_1/kernel/Adam:0\n",
      "[54.019]    230      Const                               ConvNet/dropout/dropout/keep_prob:0\n",
      "[54.146]    184      Const                               Adam/beta2:0\n",
      "[54.649]    4.21k    VariableV2                          ConvNet/dense/bias/Adam_1:0\n",
      "[62.503]    188      Const                               Adam/epsilon:0\n",
      "[64.652]    3.34k    VariableV2                          ConvNet/conv2d/kernel:0\n",
      "[73.855]    262      VariableV2                          ConvNet/dense_1/bias/Adam_1:0\n",
      "[75.755]    225.00M  VariableV2                          ConvNet/dense/kernel/Adam:0\n",
      "[77.961]    332      VariableV2                          ConvNet/conv2d/bias:0\n",
      "[80.445]    194      Const                               Reshape/shape:0\n",
      "[82.595]    72.22k   VariableV2                          ConvNet/conv2d_1/kernel:0\n",
      "[83.648]    184      Const                               Adam/beta1:0\n",
      "[88.137]    464      VariableV2                          ConvNet/conv2d_1/bias:0\n",
      "[89.955]    200      Const                               Adam/learning_rate:0\n",
      "[92.639]    186      VariableV2                          beta1_power:0\n",
      "[96.615]    190      VariableV2                          global_step:0\n",
      "[96.793]    225.00M  VariableV2                          ConvNet/dense/kernel/Adam_1:0\n",
      "[99.336]    226      Const                               global_step/Initializer/zeros:0\n",
      "[102.674]   4.20k    VariableV2                          ConvNet/dense/bias:0\n",
      "[110.314]   222      Const                               gradients/Mean_grad/Reshape:0\n",
      "[114.174]   227      IsVariableInitialized               global_step/IsVariableInitialized:0\n",
      "[116.260]   72.23k   Identity                            ConvNet/conv2d_1/kernel/read:0\n",
      "[118.419]   225.00M  VariableV2                          ConvNet/dense/kernel:0\n",
      "[124.458]   196      Identity                            beta1_power/read:0\n",
      "[126.836]   44.21k   VariableV2                          ConvNet/dense_1/kernel:0\n",
      "[128.320]   342      Identity                            ConvNet/conv2d/bias/read:0\n",
      "[128.482]   224      RefSwitch                           global_step/cond/read/Switch:1\n",
      "[133.775]   218      Switch                              global_step/cond/Switch_1:1\n",
      "[139.039]   4.21k    Identity                            ConvNet/dense/bias/read:0\n",
      "[143.642]   208      Merge                               global_step/cond/Merge:1\n",
      "[145.972]   474      Identity                            ConvNet/conv2d_1/bias/read:0\n",
      "[148.197]   248      VariableV2                          ConvNet/dense_1/bias:0\n",
      "[154.269]   44.22k   Identity                            ConvNet/dense_1/kernel/read:0\n",
      "[157.391]   3.35k    Identity                            ConvNet/conv2d/kernel/read:0\n",
      "[158.780]   212      Merge                               global_step/cond/Merge:0\n",
      "[177.207]   186      VariableV2                          beta2_power:0\n",
      "[177.379]   258      Identity                            ConvNet/dense_1/bias/read:0\n",
      "[178.342]   258      VariableV2                          ConvNet/dense_1/bias/Adam:0\n",
      "[180.739]   198      Snapshot                            global_step/add:0\n",
      "[185.869]   196      Identity                            beta2_power/read:0\n",
      "[565.793]   456      IteratorGetNext                     IteratorGetNext:1\n",
      "[567.481]   2.00M    IteratorGetNext                     IteratorGetNext:0\n",
      "[575.412]   436      Reshape                             Reshape:0\n",
      "[598.572]   302      Cast                                Cast:0\n",
      "[609.761]   60.06M   Conv2D                              ConvNet/conv2d/Conv2D:0\n",
      "[1684.521]  60.06M   BiasAdd                             ConvNet/conv2d/BiasAdd:0\n",
      "[2713.484]  60.06M   Relu                                ConvNet/conv2d/Relu:0\n",
      "[3706.409]  15.02M   MaxPool                             ConvNet/max_pooling2d/MaxPool:0\n",
      "[3885.004]  270      ShapeN                              gradients/ConvNet/conv2d_1/Conv2D_grad/ShapeN:1\n",
      "[3914.905]  270      ShapeN                              gradients/ConvNet/conv2d_1/Conv2D_grad/ShapeN:0\n",
      "[3950.180]  28.13M   Conv2D                              ConvNet/conv2d_1/Conv2D:0\n",
      "[4391.232]  28.13M   BiasAdd                             ConvNet/conv2d_1/BiasAdd:0\n",
      "[4615.493]  225.00M  Identity                            ConvNet/dense/kernel/read:0\n",
      "[4717.955]  28.13M   Relu                                ConvNet/conv2d_1/Relu:0\n",
      "[4923.340]  7.03M    MaxPool                             ConvNet/max_pooling2d_1/MaxPool:0\n",
      "[4982.571]  284      Shape                               gradients/ConvNet/Flatten/flatten/Reshape_grad/Shape:0\n",
      "[4990.812]  238      StridedSlice                        ConvNet/Flatten/flatten/strided_slice:0\n",
      "[4997.955]  246      Pack                                ConvNet/Flatten/flatten/Reshape/shape:0\n",
      "[5006.518]  7.03M    Reshape                             ConvNet/Flatten/flatten/Reshape:0\n",
      "[6243.955]  128.21k  MatMul                              ConvNet/dense/MatMul:0\n",
      "[6255.624]  128.21k  BiasAdd                             ConvNet/dense/BiasAdd:0\n",
      "[6265.872]  268      Shape                               gradients/ConvNet/dropout/dropout/div_grad/Shape:0\n",
      "[6274.177]  300      BroadcastGradientArgs               gradients/ConvNet/dropout/dropout/div_grad/BroadcastGradientArgs:1\n",
      "[6274.339]  128.22k  Mul                                 ConvNet/dropout/dropout/div:0\n",
      "[6285.159]  288      BroadcastGradientArgs               gradients/ConvNet/dropout/dropout/div_grad/BroadcastGradientArgs:0\n",
      "[6292.807]  128.27k  RandomUniform                       ConvNet/dropout/dropout/random_uniform/RandomUniform:0\n",
      "[6301.847]  128.25k  Snapshot                            ConvNet/dropout/dropout/random_uniform/mul:0\n",
      "[6308.699]  128.25k  Snapshot                            ConvNet/dropout/dropout/random_uniform:0\n",
      "[6316.127]  128.22k  Add                                 ConvNet/dropout/dropout/add:0\n",
      "[6326.178]  128.23k  Floor                               ConvNet/dropout/dropout/Floor:0\n",
      "[6337.583]  128.22k  Mul                                 ConvNet/dropout/dropout/mul:0\n",
      "[6348.467]  1.58k    MatMul                              ConvNet/dense_1/MatMul:0\n",
      "[6354.574]  1.59k    BiasAdd                             ConvNet/dense_1/BiasAdd:0\n",
      "[6360.408]  1.68k    SparseSoftmaxCrossEntropyWithLogits SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits:1\n",
      "[6360.444]  436      SparseSoftmaxCrossEntropyWithLogits SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits:0\n",
      "[6369.859]  218      Shape                               gradients/Mean_grad/Shape:0\n",
      "[6377.367]  212      Size                                gradients/Mean_grad/Prod:0\n",
      "[6377.596]  172      Mean                                Mean:0\n",
      "[6387.077]  342      Tile                                gradients/Mean_grad/Tile:0\n",
      "[6387.180]  220      Snapshot                            gradients/Mean_grad/floordiv:0\n",
      "[6390.432]  181      ScalarSummary                       loss:0\n",
      "[6399.614]  212      Cast                                gradients/Mean_grad/Cast:0\n",
      "[6403.551]  209      MergeSummary                        Merge/MergeSummary:0\n",
      "[6407.232]  348      RealDiv                             gradients/Mean_grad/truediv:0\n",
      "[6418.005]  492      ExpandDims                          gradients/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims:0\n",
      "[6426.167]  1.72k    Mul                                 gradients/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul:0\n",
      "[6432.333]  44.26k   MatMul                              gradients/ConvNet/dense_1/MatMul_grad/MatMul_1:0\n",
      "[6432.359]  128.26k  MatMul                              gradients/ConvNet/dense_1/MatMul_grad/MatMul:0\n",
      "[6432.372]  308      BiasAddGrad                         gradients/ConvNet/dense_1/BiasAdd_grad/BiasAddGrad:0\n",
      "[6444.517]  292      ApplyAdam                           Adam/update_ConvNet/dense_1/bias/ApplyAdam:0\n",
      "[6446.452]  128.26k  Mul                                 gradients/ConvNet/dropout/dropout/mul_grad/Mul:0\n",
      "[6446.989]  44.26k   ApplyAdam                           Adam/update_ConvNet/dense_1/kernel/ApplyAdam:0\n",
      "[6456.137]  128.27k  Mul                                 gradients/ConvNet/dropout/dropout/div_grad/RealDiv:0\n",
      "[6465.011]  128.26k  Sum                                 gradients/ConvNet/dropout/dropout/div_grad/Sum:0\n",
      "[6472.548]  128.27k  Reshape                             gradients/ConvNet/dropout/dropout/div_grad/Reshape:0\n",
      "[6510.828]  225.00M  MatMul                              gradients/ConvNet/dense/MatMul_grad/MatMul_1:0\n",
      "[6510.860]  4.26k    BiasAddGrad                         gradients/ConvNet/dense/BiasAdd_grad/BiasAddGrad:0\n",
      "[6511.405]  7.03M    MatMul                              gradients/ConvNet/dense/MatMul_grad/MatMul:0\n",
      "[6518.457]  4.24k    ApplyAdam                           Adam/update_ConvNet/dense/bias/ApplyAdam:0\n",
      "[6577.551]  7.03M    Reshape                             gradients/ConvNet/Flatten/flatten/Reshape_grad/Reshape:0\n",
      "[6645.901]  28.13M   MaxPoolGrad                         gradients/ConvNet/max_pooling2d_1/MaxPool_grad/MaxPoolGrad:0\n",
      "[6851.119]  28.13M   ReluGrad                            gradients/ConvNet/conv2d_1/Relu_grad/ReluGrad:0\n",
      "[7131.028]  15.02M   Conv2DBackpropInput                 gradients/ConvNet/conv2d_1/Conv2D_grad/Conv2DBackpropInput:0\n",
      "[7131.077]  524      BiasAddGrad                         gradients/ConvNet/conv2d_1/BiasAdd_grad/BiasAddGrad:0\n",
      "[7131.077]  72.29k   Conv2DBackpropFilter                gradients/ConvNet/conv2d_1/Conv2D_grad/Conv2DBackpropFilter:0\n",
      "[7149.119]  508      ApplyAdam                           Adam/update_ConvNet/conv2d_1/bias/ApplyAdam:0\n",
      "[7153.808]  72.27k   ApplyAdam                           Adam/update_ConvNet/conv2d_1/kernel/ApplyAdam:0\n",
      "[7288.157]  60.06M   MaxPoolGrad                         gradients/ConvNet/max_pooling2d/MaxPool_grad/MaxPoolGrad:0\n",
      "[7896.112]  60.06M   ReluGrad                            gradients/ConvNet/conv2d/Relu_grad/ReluGrad:0\n",
      "[8528.311]  392      BiasAddGrad                         gradients/ConvNet/conv2d/BiasAdd_grad/BiasAddGrad:0\n",
      "[8528.334]  3.41k    Conv2DBackpropFilter                gradients/ConvNet/conv2d/Conv2D_grad/Conv2DBackpropFilter:0\n",
      "[8550.162]  3.38k    ApplyAdam                           Adam/update_ConvNet/conv2d/kernel/ApplyAdam:0\n",
      "[8555.822]  376      ApplyAdam                           Adam/update_ConvNet/conv2d/bias/ApplyAdam:0\n",
      "[9203.307]  184      Mul                                 Adam/mul_1:0\n",
      "[9203.337]  180      Mul                                 Adam/mul:0\n",
      "[9203.337]  225.00M  ApplyAdam                           Adam/update_ConvNet/dense/kernel/ApplyAdam:0\n",
      "[9211.522]  186      Assign                              Adam/Assign:0\n",
      "[9212.966]  188      Const                               Adam/value:0\n",
      "[9213.008]  190      Assign                              Adam/Assign_1:0\n",
      "[9223.520]  176      AssignAdd                           Adam:0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfdbg> pt IteratorGetNext:0\n",
      "Tensor \"IteratorGetNext:0:DebugIdentity\":\n",
      "  dtype: float32\n",
      "  shape: (32, 128, 128, 1)\n",
      "\n",
      "array([[[[5.0367340e-03],\n",
      "         [9.1203925e-04],\n",
      "         [1.7060767e-03],\n",
      "         ...,\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00]],\n",
      "\n",
      "        [[8.0864951e-02],\n",
      "         [1.2049393e-01],\n",
      "         [1.6552385e-02],\n",
      "         ...,\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00]],\n",
      "\n",
      "        [[2.3539671e-01],\n",
      "         [5.4855898e-02],\n",
      "         [7.2040204e-03],\n",
      "         ...,\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.4087759e-01],\n",
      "         [3.1529022e-03],\n",
      "         [1.0121285e-03],\n",
      "         ...,\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00]],\n",
      "\n",
      "        [[3.3772483e-01],\n",
      "         [2.0449623e-02],\n",
      "         [9.1168098e-03],\n",
      "         ...,\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00]],\n",
      "\n",
      "        [[7.3427019e+00],\n",
      "         [4.0311604e+00],\n",
      "         [1.4965750e+00],\n",
      "         ...,\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00]]],\n",
      "\n",
      "\n",
      "       [[[2.0309985e-03],\n",
      "         [1.0082105e-02],\n",
      "         [2.9586474e-03],\n",
      "         ...,\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00]],\n",
      "\n",
      "        [[6.7401975e-01],\n",
      "         [3.6972231e-01],\n",
      "         [1.3534473e-01],\n",
      "         ...,\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00]],\n",
      "\n",
      "        [[7.0971143e-01],\n",
      "         [6.0420394e-01],\n",
      "         [6.5535426e-01],\n",
      "         ...,\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.3738632e+00],\n",
      "         [3.3951631e-01],\n",
      "         [1.8967974e-01],\n",
      "         ...,\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00]],\n",
      "\n",
      "        [[1.0675437e+00],\n",
      "         [1.0593653e+00],\n",
      "         [9.5525455e-01],\n",
      "         ...,\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00]],\n",
      "\n",
      "        [[1.2882293e+01],\n",
      "         [1.1113700e+01],\n",
      "         [3.1405492e+00],\n",
      "         ...,\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00]]],\n",
      "\n",
      "\n",
      "       [[[2.2783799e-03],\n",
      "         [3.6249659e-03],\n",
      "         [6.2428444e-04],\n",
      "         ...,\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00]],\n",
      "\n",
      "        [[2.0074274e-02],\n",
      "         [1.5152919e-02],\n",
      "         [1.1400884e-02],\n",
      "         ...,\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00]],\n",
      "\n",
      "        [[3.3920124e-04],\n",
      "         [1.2606266e-03],\n",
      "         [6.5852073e-04],\n",
      "         ...,\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[9.5670037e-02],\n",
      "         [3.6696871e-03],\n",
      "         [1.5896049e-03],\n",
      "         ...,\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00]],\n",
      "\n",
      "        [[1.9229609e-01],\n",
      "         [2.9073713e-02],\n",
      "         [1.3629823e-02],\n",
      "         ...,\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00]],\n",
      "\n",
      "        [[1.1741702e+01],\n",
      "         [4.9103518e+00],\n",
      "         [1.7130142e+00],\n",
      "         ...,\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[7.7150419e-04],\n",
      "         [1.8015866e-04],\n",
      "         [2.8252974e-04],\n",
      "         ...,\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00]],\n",
      "\n",
      "        [[3.7223578e-04],\n",
      "         [1.1387952e-04],\n",
      "         [6.7785277e-04],\n",
      "         ...,\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00]],\n",
      "\n",
      "        [[1.0958644e-02],\n",
      "         [6.4789988e-03],\n",
      "         [9.4015058e-03],\n",
      "         ...,\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[2.1934201e-01],\n",
      "         [7.6654479e-03],\n",
      "         [6.9918088e-03],\n",
      "         ...,\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00]],\n",
      "\n",
      "        [[5.7737887e-01],\n",
      "         [1.1518417e-01],\n",
      "         [7.6720387e-02],\n",
      "         ...,\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00]],\n",
      "\n",
      "        [[3.4421993e+01],\n",
      "         [1.4697248e+01],\n",
      "         [5.4236455e+00],\n",
      "         ...,\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00]]],\n",
      "\n",
      "\n",
      "       [[[1.7108157e-02],\n",
      "         [7.5320546e-03],\n",
      "         [4.4757430e-03],\n",
      "         ...,\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00]],\n",
      "\n",
      "        [[3.2197377e-03],\n",
      "         [1.2628210e-04],\n",
      "         [1.8457406e-04],\n",
      "         ...,\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00]],\n",
      "\n",
      "        [[1.2959903e-02],\n",
      "         [2.4498003e-03],\n",
      "         [2.8058700e-03],\n",
      "         ...,\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[2.3478320e-01],\n",
      "         [9.9063860e-03],\n",
      "         [4.7699730e-03],\n",
      "         ...,\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00]],\n",
      "\n",
      "        [[5.7605374e-01],\n",
      "         [8.2944468e-02],\n",
      "         [3.9251782e-02],\n",
      "         ...,\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00]],\n",
      "\n",
      "        [[3.7180660e+01],\n",
      "         [1.5827678e+01],\n",
      "         [5.7906785e+00],\n",
      "         ...,\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00]]],\n",
      "\n",
      "\n",
      "       [[[1.0641136e-02],\n",
      "         [1.4121970e-02],\n",
      "         [6.3166148e-03],\n",
      "         ...,\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00]],\n",
      "\n",
      "        [[1.7924467e-03],\n",
      "         [2.2156721e-03],\n",
      "         [6.2935648e-04],\n",
      "         ...,\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00]],\n",
      "\n",
      "        [[1.6677203e-03],\n",
      "         [6.0291244e-03],\n",
      "         [9.6972304e-04],\n",
      "         ...,\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[2.3805118e-01],\n",
      "         [2.0015663e-01],\n",
      "         [1.5056396e-01],\n",
      "         ...,\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00]],\n",
      "\n",
      "        [[1.6226815e+00],\n",
      "         [2.1676198e-01],\n",
      "         [6.7200673e-01],\n",
      "         ...,\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00]],\n",
      "\n",
      "        [[1.7277464e+01],\n",
      "         [9.3003159e+00],\n",
      "         [1.1262628e+00],\n",
      "         ...,\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00],\n",
      "         [0.0000000e+00]]]], dtype=float32)\n",
      "\n",
      "tfdbg> exit\n",
      "INFO:tensorflow:loss = 2.792623, step = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: user exited from debugger CLI: Calling sys.exit(1).\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\philip~1\\docume~1\\audiotf\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2969: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# Function to parse the TFRecord\n",
    "def _parse_(serialized_example):\n",
    "    feature_list = {'note': tf.FixedLenSequenceFeature(shape=[], dtype=tf.int64, allow_missing=True),\n",
    "                'note_str': tf.FixedLenSequenceFeature(shape=[], dtype=tf.string, allow_missing=True),\n",
    "                'instrument': tf.FixedLenSequenceFeature(shape=[], dtype=tf.int64, allow_missing=True),\n",
    "                'instrument_str': tf.FixedLenSequenceFeature(shape=[], dtype=tf.string, allow_missing=True),\n",
    "                'pitch': tf.FixedLenSequenceFeature(shape=[], dtype=tf.int64, allow_missing=True),\n",
    "                'velocity': tf.FixedLenSequenceFeature(shape=[], dtype=tf.int64, allow_missing=True),\n",
    "                'sample_rate': tf.FixedLenSequenceFeature(shape=[], dtype=tf.int64, allow_missing=True),\n",
    "                'audio': tf.FixedLenSequenceFeature(shape=[1], dtype=tf.float32, allow_missing=True),\n",
    "                'qualities': tf.FixedLenSequenceFeature(shape=[1], dtype=tf.int64, allow_missing=True),\n",
    "                'qualities_str': tf.FixedLenSequenceFeature(shape=[1], dtype=tf.string, allow_missing=True),\n",
    "                'instrument_family': tf.FixedLenSequenceFeature(shape=[], dtype=tf.int64, allow_missing=True),\n",
    "                'instrument_family_str': tf.FixedLenSequenceFeature(shape=[], dtype=tf.string, allow_missing=True),\n",
    "                'instrument_source': tf.FixedLenSequenceFeature(shape=[], dtype=tf.int64, allow_missing=True),\n",
    "                'instrument_source_str': tf.FixedLenSequenceFeature(shape=[], dtype=tf.string, allow_missing=True)}\n",
    "    \n",
    "    # Extract example by features\n",
    "    example = tf.parse_single_example(serialized_example, feature_list)\n",
    "    \n",
    "    # Convert audio data to normalized spectrogram\n",
    "    spectrogram = audio_ops.audio_spectrogram(example[\"audio\"], window_size=1024, stride=64)\n",
    "    max_val = tf.reduce_max(spectrogram, axis=None)\n",
    "    min_const = tf.constant(255.)\n",
    "    brightness_const = tf.divide(min_const, max_val)   # Calculate normalization constant\n",
    "    brightened_spect = tf.multiply(spectrogram, brightness_const)\n",
    "    minned_spectrogram = tf.minimum(brightened_spect, min_const) # Remove other spikes?\n",
    "    expanded = tf.expand_dims(minned_spectrogram, -1)\n",
    "    resized = tf.image.resize_bilinear(expanded, [128, 128])\n",
    "    squeezed = tf.squeeze(resized, 0)\n",
    "    flipped = tf.image.flip_left_right(squeezed)\n",
    "    normalized_spectrogram = tf.image.transpose_image(flipped)\n",
    "    \n",
    "    # Cast data to input format required by model\n",
    "    image = normalized_spectrogram\n",
    "    label = tf.cast(example['instrument_family'],tf.int64)\n",
    "    return (dict({'image':image}),label)\n",
    "\n",
    "\n",
    "\n",
    "# Define the data input function for training\n",
    "def tfrecord_train_input_fn(batch_size=32):\n",
    "    tfrecord_dataset = tf.data.TFRecordDataset(TRAINING_DATA)\n",
    "    tfrecord_dataset = tfrecord_dataset.map(lambda   x:_parse_(x)).shuffle(True).batch(batch_size)\n",
    "    tfrecord_iterator = tfrecord_dataset.make_one_shot_iterator()\n",
    "    \n",
    "    return tfrecord_iterator.get_next()\n",
    "\n",
    "# Train the Model\n",
    "# With debug\n",
    "hooks = [tf_debug.LocalCLIDebugHook(ui_type=\"readline\")]\n",
    "model.train(tfrecord_train_input_fn, steps=NUM_STEPS, hooks=hooks)\n",
    "# without debug\n",
    "# model.train(tfrecord_train_input_fn, steps=NUM_STEPS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the Model\n",
    "# Define the input function for evaluating\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'images': mnist.test.images}, y=mnist.test.labels,\n",
    "    batch_size=BATCH_SIZE, shuffle=False)\n",
    "# Use the Estimator 'evaluate' method\n",
    "model.evaluate(input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict single images\n",
    "n_images = 4\n",
    "# Get images from test set\n",
    "test_images = mnist.test.images[:n_images]\n",
    "# Prepare the input data\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'images': test_images}, shuffle=False)\n",
    "# Use the model to predict the images class\n",
    "preds = list(model.predict(input_fn))\n",
    "\n",
    "# Display\n",
    "for i in range(n_images):\n",
    "    plt.imshow(np.reshape(test_images[i], [28, 28]), cmap='gray')\n",
    "    plt.show()\n",
    "    print(\"Model prediction:\", preds[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
